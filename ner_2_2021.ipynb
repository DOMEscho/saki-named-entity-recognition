{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Resumee_NER_Spacy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DOMEscho/saki-named-entity-recognition/blob/main/ner_2_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yjL03CKOoEk"
      },
      "source": [
        "Getting started with Spacy<br>\n",
        "Import data.<br>\n",
        "We repeat the preprocessing from the previous homework."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOxAAu3cOm9D",
        "outputId": "b2f790b3-d335-460e-a611-fd17d9a9d397"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOc5LrSCPSEC"
      },
      "source": [
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd_X8KyOPWlJ"
      },
      "source": [
        "os.chdir( \"/content/gdrive/MyDrive/flair\" ) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBNxx2f8Pcmq"
      },
      "source": [
        "path_to_data = os.getcwd() + '/Entity Recognition in Resumes.json'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUKwMlfkaR2n",
        "outputId": "aa0a93f1-05e3-48de-e48f-ca8865e09158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "myfile = open( path_to_data, \"r\", encoding = \"utf-8\" )\n",
        "\n",
        "imported_data = []\n",
        "\n",
        "for datum in myfile:\n",
        "  # TODO process data\n",
        "  imported_data.append(datum)\n",
        "\n",
        "myfile.close()\n",
        "\n",
        "# TODO print first line\n",
        "print(imported_data[0])\n",
        "# TODO print how many resumees were read in\n",
        "print(len(imported_data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"content\": \"Afreen Jamadar\\nActive member of IIIT Committee in Third year\\n\\nSangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\\n\\nI wish to use my knowledge, skills and conceptual understanding to create excellent team\\nenvironments and work consistently achieving organization objectives believes in taking initiative\\nand work to excellence in my work.\\n\\nWORK EXPERIENCE\\n\\nActive member of IIIT Committee in Third year\\n\\nCisco Networking -  Kanpur, Uttar Pradesh\\n\\norganized by Techkriti IIT Kanpur and Azure Skynet.\\nPERSONALLITY TRAITS:\\n• Quick learning ability\\n• hard working\\n\\nEDUCATION\\n\\nPG-DAC\\n\\nCDAC ACTS\\n\\n2017\\n\\nBachelor of Engg in Information Technology\\n\\nShivaji University Kolhapur -  Kolhapur, Maharashtra\\n\\n2016\\n\\nSKILLS\\n\\nDatabase (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\\n\\nhttps://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\",\"annotation\":[{\"label\":[\"Email Address\"],\"points\":[{\"start\":1155,\"end\":1198,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Links\"],\"points\":[{\"start\":1143,\"end\":1239,\"text\":\"https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\"}]},{\"label\":[\"Skills\"],\"points\":[{\"start\":743,\"end\":1140,\"text\":\"Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":729,\"end\":732,\"text\":\"2016\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":675,\"end\":702,\"text\":\"Shivaji University Kolhapur \"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":631,\"end\":672,\"text\":\"Bachelor of Engg in Information Technology\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":625,\"end\":629,\"text\":\"2017\\n\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":614,\"end\":622,\"text\":\"CDAC ACTS\"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":606,\"end\":611,\"text\":\"PG-DAC\"}]},{\"label\":[\"Companies worked at\"],\"points\":[{\"start\":438,\"end\":453,\"text\":\"Cisco Networking\"}]},{\"label\":[\"Email Address\"],\"points\":[{\"start\":104,\"end\":147,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Location\"],\"points\":[{\"start\":62,\"end\":67,\"text\":\"Sangli\"}]},{\"label\":[\"Name\"],\"points\":[{\"start\":0,\"end\":13,\"text\":\"Afreen Jamadar\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1527844872000,\"last_updated_at\":1537724086000,\"sec_taken\":0,\"last_updated_by\":\"BIQNZm4INNfvByMqkaVwVt6OZTv2\",\"status\":\"done\",\"evaluation\":\"CORRECT\"}}\n",
            "\n",
            "701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxQojbZyPrkh"
      },
      "source": [
        "import json"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axwa389baXDN"
      },
      "source": [
        "mapped_data = [ json.loads( datum ) for datum in imported_data  ]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2FaAX-xabje",
        "outputId": "1dd20831-3e6e-40b9-c01e-6513f4af720b"
      },
      "source": [
        "## data conversion method\n",
        "def convert_data(data):\n",
        "    \"\"\"\n",
        "    Creates NER training data in Spacy format from JSON dataset\n",
        "    Outputs the Spacy training data which can be used for Spacy training.\n",
        "    \"\"\"\n",
        "    text = data['content']\n",
        "    entities = []\n",
        "    if data['annotation'] is not None:\n",
        "        for annotation in data['annotation']:\n",
        "            # only a single point in text annotation.\n",
        "            point = annotation['points'][0]\n",
        "            labels = annotation['label']\n",
        "            # handle both list of labels or a single label.\n",
        "            if not isinstance(labels, list):\n",
        "                labels = [labels]\n",
        "            for label in labels:\n",
        "                # dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
        "                entities.append((point['start'], point['end'] + 1, label))\n",
        "    return (text, {\"entities\": entities})\n",
        "   \n",
        "## TODO using a loop or list comprehension, convert each resume in mapped_data using the convert function above, \n",
        "## storing the result\n",
        "converted_resumes = [convert_data(resume) for resume in mapped_data]\n",
        "## TODO print the number of resumes in converted resumes \n",
        "print( len(converted_resumes) )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GapDFuttaqpk"
      },
      "source": [
        "# TODO filter out the resumees whose entities have no entries.\n",
        "converted_complete_resumees = list( filter(lambda r: len(r[1]['entities']) > 0 , converted_resumes) )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-UWPUvfbo0l"
      },
      "source": [
        "Up until now, you could reuse the code from the previous notebook, now, something new comes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYhNshfBbl8d",
        "outputId": "99666535-5861-4778-a66a-c38dd3623123"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "print(nlp)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<spacy.lang.en.English object at 0x7f6f82fb39d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AqzhVdHb-xO"
      },
      "source": [
        "__nlp__ is Spacy's English language model. For this model, a pretrained NER-model exists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDHFtX6Lb-CY",
        "outputId": "130d7388-b5a1-4a39-a0b2-196997f14a58"
      },
      "source": [
        "ner = nlp.get_pipe('ner')\n",
        "labels = ner.labels\n",
        "print(labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBy9Uo20cZH2"
      },
      "source": [
        "__Question 1__: Explain the labels __GPE__, __FAC__, __NORP__.<br>\n",
        "Which of these labels from __ner__ do you think will Spacy recognize in the resumees?<br>\n",
        "__Task 1__: choose a resumee."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0mskJKlO7Xt",
        "outputId": "1e9226b9-a634-41c8-f411-fdd31dbdd607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"GPE: \", spacy.explain('GPE'))\n",
        "print(\"FAC: \", spacy.explain('FAC'))\n",
        "print(\"NORP: \", spacy.explain('NORP'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPE:  Countries, cities, states\n",
            "FAC:  Buildings, airports, highways, bridges, etc.\n",
            "NORP:  Nationalities or religious or political groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yXayIFffE7F",
        "outputId": "de4ea6b1-224b-431c-8532-37851a9394b4"
      },
      "source": [
        "# TODO get a single resume text and print it out.\n",
        "restxt = converted_complete_resumees[42][0]\n",
        "## print it out, removing extraneous spaces\n",
        "print(\"\\n\".join(restxt.split('\\n\\n')))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Navas Koya\n",
            "Test Engineer\n",
            "Mangalore, Karnataka - Email me on Indeed: indeed.com/r/Navas-Koya/23c1e4e94779b465\n",
            "Willing to relocate to: Mangalore, Karnataka - Bangalore, Karnataka - Chennai, Tamil Nadu\n",
            "WORK EXPERIENCE\n",
            "System Engineer\n",
            "Infosys -\n",
            "August 2014 to Present\n",
            ".NET application Maintenance and do the code changes if required\n",
            "Test Engineer\n",
            "Infosys -\n",
            "June 2015 to February 2016\n",
            "PrProject 2:\n",
            "Title: RBS W&G Proving testing.\n",
            "Technology: Manual testing\n",
            "Role: Software Test Engineer\n",
            "Domain: Banking\n",
            "Description:\n",
            "Write test cases & descriptions. Review the entries. Upload and map the documents into\n",
            "HP QC. Execute the testing operations in TPROD mainframe. Upload the result in QC along with\n",
            "the proof.\n",
            "Roles and Responsibilities:\n",
            "•Prepared the Test Scenarios\n",
            "•Prepared and Executed Test Cases\n",
            "•Performed functional, Regression testing, Sanity testing.\n",
            "•Reviewed the Test Reports and Preparing Test Summary Report.\n",
            "•Upload Test cases to the QC.\n",
            "•Execute in TPROD Mainframe.\n",
            "•Defect Track and Report.\n",
            "Test Executive\n",
            "Infosys Limited -\n",
            "August 2014 to May 2015\n",
            "https://www.indeed.com/r/Navas-Koya/23c1e4e94779b465?isid=rex-download&ikw=download-top&co=IN\n",
            "\n",
            "Project 1:\n",
            "Title: CAWP (Compliance Automated Work Paper)\n",
            "Technology: Manual testing\n",
            "Role: Software Test Executive\n",
            "Domain: Banking\n",
            "Description:\n",
            "The Admin can create and maintain annual test plan, and users can only view and add\n",
            "details. Testers will get Business Requirement which explains the flows and Functional\n",
            "requirements which gives the full detail of the project.\n",
            "Roles and Responsibilities:\n",
            "•Prepared the Test Scenarios\n",
            "•Prepared and Executed Test Cases\n",
            "•Performed functional, Regression testing, Sanity testing.\n",
            "•Reviewed the Test Reports and Preparing Test Summary Report.\n",
            "•Defect Track and Report.\n",
            "EDUCATION\n",
            "Bachelor of Computer Applications\n",
            "Mangalore University, Mangalore\n",
            "June 2011 to April 2014\n",
            "SKILLS\n",
            "C# (Less than 1 year), .NET, SQL Server, Css, Html5\n",
            "ADDITIONAL INFORMATION\n",
            "Bachelor of computer application: with 74% from Milagres College, Kallianpur under\n",
            "Mangalore University, Karnataka.\n",
            "Navas Najeer Koya 2\n",
            "SKILL SET • ASP.NET, C# • QA tools\n",
            "• Coding and modularization • Excellent communication skills\n",
            "• VB, VB.net, ASP • Technical specifications creation\n",
            "• HTML • System backups\n",
            "• Sql server 2005, Oracle • System upgrades\n",
            "• Java/C/C++ • Excellent problem-solving abilities\n",
            "Navas Najeer Koya 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m39CIXirJ5bv"
      },
      "source": [
        "Next, we let __nlp__ process that single resumee.<br>\n",
        "__Task 2__: print the results in __doc__. For each result, print the underlying text and the label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp961WAxfW8N",
        "outputId": "cb13d3f0-caec-4a36-a0b4-a46db3be8a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(restxt)\n",
        "# TODO  Print the results in doc. For each result, print the text and the label.\n",
        "print(f'{\"Text:\":<50} | {\"Label\":<30}')\n",
        "print(\"-\"*80)\n",
        "for token in doc.ents:\n",
        "  print(f'{token.text:<50} | {token.label_:<30}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:                                              | Label                         \n",
            "--------------------------------------------------------------------------------\n",
            "Navas Koya                                         | PERSON                        \n",
            "Mangalore                                          | GPE                           \n",
            "Karnataka                                          | PERSON                        \n",
            "Karnataka                                          | PERSON                        \n",
            "Karnataka - Chennai                                | ORG                           \n",
            "Tamil Nadu                                         | PERSON                        \n",
            "System Engineer                                    | ORG                           \n",
            "Infosys                                            | GPE                           \n",
            "August 2014                                        | DATE                          \n",
            "Infosys                                            | GPE                           \n",
            "June 2015 to February 2016                         | DATE                          \n",
            "Roles                                              | PERSON                        \n",
            "•Prepared                                          | PERSON                        \n",
            "QC                                                 | LAW                           \n",
            "TPROD Mainframe                                    | GPE                           \n",
            "Test Executive                                     | ORG                           \n",
            "Infosys Limited -                                  | ORG                           \n",
            "August 2014                                        | DATE                          \n",
            "May 2015                                           | DATE                          \n",
            "Project 1                                          | CARDINAL                      \n",
            "Business Requirement                               | ORG                           \n",
            "Functional                                         | LOC                           \n",
            "Roles                                              | PERSON                        \n",
            "•Prepared                                          | PERSON                        \n",
            "Bachelor of Computer Applications\n",
            "\n",
            "                | ORG                           \n",
            "June 2011 to April 2014                            | DATE                          \n",
            "SKILLS                                             | ORG                           \n",
            "Less than 1 year                                   | DATE                          \n",
            "SQL                                                | ORG                           \n",
            "Server                                             | PRODUCT                       \n",
            "Css                                                | ORG                           \n",
            "74%                                                | PERCENT                       \n",
            "Milagres College                                   | ORG                           \n",
            "Kallianpur                                         | GPE                           \n",
            "Mangalore University                               | ORG                           \n",
            "Karnataka                                          | PERSON                        \n",
            "Navas Najeer                                       | PERSON                        \n",
            "2                                                  | CARDINAL                      \n",
            "ASP                                                | ORG                           \n",
            "Sql                                                | ORG                           \n",
            "2005                                               | DATE                          \n",
            "Oracle • System                                    | ORG                           \n",
            "Java/C/C++                                         | ORG                           \n",
            "Navas Najeer Koya                                  | PERSON                        \n",
            "3                                                  | CARDINAL                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xok9PDMplMNe"
      },
      "source": [
        "__Question 2__: How well did Spacy perform at recognizing the labels for this text?<br>\n",
        "When Spacy predicted the labels for this resumee, a pretrained model was used.<br>\n",
        "__Task 3__: print for this resumee the original labels and their corresponding text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8eIm9lXlznU",
        "outputId": "e145ad75-b5db-49ef-f2f5-18bddd0f9480"
      },
      "source": [
        "# TODO print for that resumee the original labels and their corresponding text.\n",
        "\n",
        "labeled_ents = converted_complete_resumees[42][1]['entities']\n",
        "print(f'{\"Text:\":<50} | {\"Label\":<30}')\n",
        "print(\"-\"*80)\n",
        "text_body = converted_complete_resumees[42][0] \n",
        "for ent in labeled_ents:\n",
        "  start = ent[0]\n",
        "  end = ent[1]\n",
        "  label = ent[2]\n",
        "  text = text_body[start:end]\n",
        "  print(f'{text:<100} | {label:<30}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:                                              | Label                         \n",
            "--------------------------------------------------------------------------------\n",
            "SKILL SET • ASP.NET, C# • QA tools\n",
            "\n",
            "• Coding and modularization • Excellent communication skills\n",
            "\n",
            "• VB, VB.net, ASP • Technical specifications creation\n",
            "\n",
            "• HTML • System backups\n",
            "\n",
            "• Sql server 2005, Oracle • System upgrades\n",
            "\n",
            "• Java/C/C++ • Excellent problem-solving abilities\n",
            "\n",
            "Navas Najeer Koya 3 | Skills                        \n",
            "Mangalore                                                                                            | Location                      \n",
            "C# (Less than 1 year), .NET, SQL Server, Css, Html5\n",
            "                                                 | Skills                        \n",
            " 2014                                                                                                | Graduation Year               \n",
            "Mangalore                                                                                            | Location                      \n",
            "Mangalore                                                                                            | Location                      \n",
            "Bachelor of Computer Application                                                                     | Degree                        \n",
            " 2014                                                                                                | Graduation Year               \n",
            "Infosys                                                                                              | Companies worked at           \n",
            "Test Engineer\n",
            "                                                                                       | Designation                   \n",
            "Infosys                                                                                              | Companies worked at           \n",
            "Test Engineer\n",
            "                                                                                       | Designation                   \n",
            " 2014                                                                                                | Graduation Year               \n",
            "Infosys                                                                                              | Companies worked at           \n",
            "System Engineer                                                                                      | Designation                   \n",
            "Mangalore                                                                                            | Location                      \n",
            "Mangalore                                                                                            | Location                      \n",
            "Test Engineer\n",
            "                                                                                       | Designation                   \n",
            "Navas Koya                                                                                           | Name                          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBHplvL2KHXO"
      },
      "source": [
        "__Question 3__: Compare the performance of the pretrained model __nlp__ and the true labels. Did Spacy perform well? If not, try to explain why.<br>\n",
        "__Task 4__: Remember last homework? You chose three labels. Select all the resumees, in which all three labels appear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wELEGAoEKDwf",
        "outputId": "a17f97f5-dd4e-451a-e52c-8e2cb01bc599"
      },
      "source": [
        "# TODO fill in your chosen labels in chosen_entity_labels\n",
        "chosen_entity_labels = [ 'Degree', 'Companies worked at', 'Skills' ]\n",
        "\n",
        "## this method gathers all resumes which have all of the chosen entites above.\n",
        "def gather_candidates(dataset,entity_labels):\n",
        "    candidates = list()\n",
        "    for resume in dataset:\n",
        "        res_ent_labels = list(zip(*resume[1][\"entities\"]))[2]\n",
        "        if set(entity_labels).issubset(res_ent_labels):\n",
        "            candidates.append(resume)\n",
        "    return candidates\n",
        "\n",
        "training_data = gather_candidates( converted_complete_resumees, chosen_entity_labels )\n",
        "print(\"Gathered {} training examples\".format(len(training_data)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gathered 437 training examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSDI7dDDLBbW"
      },
      "source": [
        "__Task 5__: Next, we want to remove all other entities, since we only want to train NER for the three entities in __chosen_entity_labels__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DBr_VzxLNqe"
      },
      "source": [
        "## filter all annotation based on filter list\n",
        "def filter_ents(ents, filter):\n",
        "    filtered = [ent for ent in ents if ent[2] in filter]\n",
        "    return filtered\n",
        "\n",
        "## TODO use method above to remove all but relevant (chosen) entity annotations and store in X variable. X shall contain all\n",
        "## the resumees from training_data, but their entity annotations shall be filtered using the function from above.\n",
        "X = []\n",
        "for sample in training_data:\n",
        "  ents = sample[1][\"entities\"]\n",
        "  sample[1][\"entities\"] = filter_ents(ents, chosen_entity_labels)\n",
        "  X.append(sample)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZpyxtX6NteV"
      },
      "source": [
        "__Task 6__: Some resumees cause trouble. We filter these out with the following lines of code.<br>\n",
        "First, use __add_label__ to add your chosen labels to the __ner__ model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqwcgW_xX18e",
        "outputId": "6f5a3486-66da-49c5-eefc-eb9a30401e14"
      },
      "source": [
        "from spacy.gold import GoldParse \n",
        "\n",
        "# TODO add your labels \n",
        "for entity_label in chosen_entity_labels:\n",
        "  ner.add_label(entity_label)\n",
        "\n",
        "\n",
        "nlp.begin_training()\n",
        "\n",
        "good = []\n",
        "\n",
        "for item in X:\n",
        "  \n",
        "  text = nlp.make_doc( item[ 0 ] )\n",
        "\n",
        "  try:\n",
        "    \n",
        "    gold = GoldParse( text, entities = item[ 1 ][ \"entities\" ] )\n",
        "\n",
        "  except:\n",
        "\n",
        "    continue\n",
        "  \n",
        "  try:\n",
        "    \n",
        "    nlp.update( [ text ], [ gold ], drop = 0.3 )\n",
        "\n",
        "  except:\n",
        "\n",
        "    pass\n",
        "\n",
        "  else:\n",
        "\n",
        "    good.append( item )\n",
        "\n",
        "print( \"Number of good samples: \" + str( len( good ) ) )\n",
        "\n",
        "print( \"\" )\n",
        "\n",
        "print( \"\" )\n",
        "\n",
        "print( \"Number of bad sampples: \" + str( len( X ) - len( good ) ) )"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of good samples: 351\n",
            "\n",
            "\n",
            "Number of bad sampples: 86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obZ93SLzyFIe"
      },
      "source": [
        "For a machine learning model, it is essential to be able to generalize. Only a model, that can generalize well is able to process new data in a meaningful way. Therefore, one usually separates the data set into two sets: the training set and the test set. The training set is used to train the model. The test set is used to evaluate the performance of the model on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0XVZPTyyh4T"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split( [ item[ 0 ] for item in good ], [ item[ 1 ] for item in good ], test_size = 0.3 )"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AcgIty-1otR"
      },
      "source": [
        "__Task 7__: Complete the following code. Shuffle __new_index__. Create the data sets __x_shuffled__ and __y_shuffled__. Use these to create minibatches, iterate over these minibatches, preprocess the data in a given minibatch using __nlp.make_doc__ and __GoldParse__. Employ __nlp.update__ to update the model using these preprocessed data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGLUALLr1rEp",
        "outputId": "e5ef8a90-627b-4be1-c69f-f9cb41461bd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "nlp.begin_training()\n",
        "\n",
        "nr_of_batches = 39#9\n",
        "\n",
        "new_index = np.arange( len( x_train ) )\n",
        "\n",
        "x_data = np.array( x_train )\n",
        "\n",
        "y_data = np.array( y_train )\n",
        "\n",
        "rng = np.random.default_rng()\n",
        "for i in range( 20 ):\n",
        "\n",
        "  rng.shuffle(new_index)\n",
        "  # TODO shuffle new_index\n",
        "\n",
        "  x_shuffled = x_data[new_index] #TODO create x_shuffled from x_data by using the shuffled new_index\n",
        "\n",
        "  y_shuffled = y_data[new_index] #TODO create y_shuffled from y_data by using the shuffled new_index\n",
        "\n",
        "  # TODO\n",
        "  # divide the data in x_shuffled and y_shuffled into minibatches of identical size\n",
        "  x_minibatches = np.array_split(x_shuffled, nr_of_batches, axis=0)\n",
        "  y_minibatches = np.array_split(y_shuffled, nr_of_batches, axis=0)\n",
        "  # iterate over these minibatches\n",
        "  for x_mbatch, y_mbatch in zip(x_minibatches, y_minibatches):\n",
        "    # preprocess the data in a minibatch using nlp.make_doc and GoldParse\n",
        "    #for raw_text, entity_offsets in train_data:\n",
        "    stringified_batch = ' '.join(x_mbatch)\n",
        "    doc = nlp.make_doc(stringified_batch)\n",
        "    print(doc)\n",
        "    \n",
        "    break\n",
        "    #example = Example.from_dict(doc, {\"entities\": entity_offsets})\n",
        "    #nlp.update([example], sgd=optimizer)\n",
        "    # use these preprocessed data and nlp.update to train the model\n",
        "  break"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sameer Kujur\n",
            "Orrisha - Email me on Indeed: indeed.com/r/Sameer-Kujur/0771f65bfa7aff96\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "App develop\n",
            "\n",
            "Microsoft -\n",
            "\n",
            "August 2016 to Present\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "Electrical engineering\n",
            "\n",
            "VSSUT,burla\n",
            "\n",
            "SKILLS\n",
            "\n",
            "Application Development, Software Testing\n",
            "\n",
            "https://www.indeed.com/r/Sameer-Kujur/0771f65bfa7aff96?isid=rex-download&ikw=download-top&co=IN Bhawana Daf\n",
            "Pune, Maharashtra - Email me on Indeed: indeed.com/r/Bhawana-Daf/d9ddb6a54519d583\n",
            "\n",
            "Seeking a career in preschool where I can utilize my teaching background strongly ,in nurturing\n",
            "young minds ,demonstrating quality teaching skills.\n",
            "\n",
            "Willing to relocate to: Viman Nagar, Maharashtra - Vadgaonsheri - Kharadi, Maharashtra\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "Preschool Teacher\n",
            "\n",
            "Pune, Maharashtra -\n",
            "\n",
            "2015 to 2018\n",
            "\n",
            "Class teacher\n",
            "\n",
            "Data Entry and Discrepancy Management\n",
            "\n",
            "Oracle Clinical\n",
            "\n",
            "4.6)\n",
            "• Knowledge of clinical trial data like Demographic Data, Adverse Events (AE), Serious Adverse\n",
            "Events (SAE), Laboratory Data (Lab Data) etc.\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "B. Sc. in Biology\n",
            "\n",
            "Government Science College -  Pandhurna, Madhya Pradesh\n",
            "\n",
            "H.S.C\n",
            "\n",
            "R.D.H.S. School -  Chhindwara, Madhya Pradesh\n",
            "\n",
            "Post Graduate Diploma in Clinical Data Management\n",
            "\n",
            "R.D.H.S. School -  Chhindwara, Madhya Pradesh\n",
            "\n",
            "SKILLS\n",
            "\n",
            "Teaching (3 years)\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "SKILLS:\n",
            "• Perform all functions related to Data Entry like First Pass and Second Pass Data Entry, review\n",
            "of Data Entry, and database update. Well versed in reading hand written patient documents.\n",
            "\n",
            "https://www.indeed.com/r/Bhawana-Daf/d9ddb6a54519d583?isid=rex-download&ikw=download-top&co=IN\n",
            "\n",
            "\n",
            "• Review, analyze, and validate clinical trial data to ensure consistency, integrity and accuracy\n",
            "based on project specific guidelines.\n",
            "\n",
            "• Maintain clinical trial data accuracy through review of case report forms for completeness and\n",
            "consistency.\n",
            "\n",
            "• Query data inconsistencies and revise case report forms in compliance with standard operating\n",
            "procedures, client guidelines and regulatory agency guidelines. Shabnam Saba\n",
            "Offshore SAP CRM Functional Consultant\n",
            "\n",
            "Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Shabnam-Saba/dc70fc366accb67f\n",
            "\n",
            "To understand the organization and to identify its needs and correlate them with my goals so as\n",
            "to apply myself to responsibility with total dedication and dynamism so as to grow along with\n",
            "the organization.\n",
            "\n",
            "Past Organization: Tata Consultancy Services as SAP CRM functional consultant (July 2014 - Jan\n",
            "2016), SAP Labs, India (from Feb 2011-June 2014), Cognizant Technology Solutions (May 2010-\n",
            "October 2010)\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "Offshore SAP CRM Functional Consultant\n",
            "\n",
            "SAP AG -\n",
            "\n",
            "July 2014 to January 2016\n",
            "\n",
            "Description: The project involves SAP IT support with respect to AGS and SAP Cloud Process .SAP\n",
            "IT support involves handling incident and service requests from SAP CRM users and customers\n",
            "across the globe.\n",
            "\n",
            "Responsibilities:\n",
            "• Problem Analysing and Handling Tickets of SAP CRM (AGS and Cloud process)\n",
            "• Handling incident and providing solution with in SLA time frame.\n",
            "• Configuring the system to resolve the issues.\n",
            "• Worked on changes to the functional specifications required as per the clients\n",
            "requirement.\n",
            "• Preparing test cases and taking approval from client before moving new changes to production.\n",
            "• Coordinated with the technical team in solving the tickets.\n",
            "\n",
            "Quality Engineer\n",
            "\n",
            "SAP Labs -\n",
            "\n",
            "July 2002 to January 2014\n",
            "\n",
            "Responsibilities:\n",
            "\n",
            "Worked in configuring and testing different areas of Framework:\n",
            "\n",
            "• Nav. Bar profile\n",
            "• Role Config key\n",
            "• Business Roles and UI Config tool\n",
            "• Creating A Business Role\n",
            "\n",
            "Functional Consultant\n",
            "\n",
            "https://www.indeed.com/r/Shabnam-Saba/dc70fc366accb67f?isid=rex-download&ikw=download-top&co=IN\n",
            "\n",
            "\n",
            "SAP Labs -\n",
            "\n",
            "March 2012 to June 2013\n",
            "\n",
            "Description:\n",
            "\n",
            "Mobile Client Technology is client technology designed for Microsoft Windows-based, occasionally\n",
            "server-connected CRM field applications. These applications offer a rich function set, such as\n",
            "SAP CRM Mobile Sales and SAP CRM Mobile Service. Mobile Sales for SAP CRM allows users to\n",
            "access all their accounts, contacts, leads, opportunities, and activities from a single point. All\n",
            "relationships between these business objects are automatically mapped in the application, which\n",
            "allows for fast and easy navigation.\n",
            "\n",
            "Responsibilities:\n",
            "Testing the various business objects:\n",
            "Opportunities, Quotation, Sales orders, Activities.\n",
            "Worked on system set up (creation of sites, subscriptions), opportunity, quotation, order\n",
            "management.\n",
            "\n",
            "5. CRM Sales ( CRM 7.01, CRM 7.02, CRM 7.03) -Feb '2011-June 2014\n",
            "\n",
            "Client: SAP Labs India\n",
            "Role: Functional Consultant\n",
            "Description:\n",
            "\n",
            "This area in SAP Customer Relationship Management (SAP CRM) enables you to manage your\n",
            "sales cycle, starting with creating appointments and business opportunities, through to managing\n",
            "sales orders, contracts, and invoicing. It also allows you to organize and structure your sales\n",
            "territories according to your business requirements.\n",
            "\n",
            "Responsibilities:\n",
            "Was involved in customizations and testing of:\n",
            "\n",
            "• Territory management\n",
            "• Account and contact management\n",
            "• Activity management, visit Planning\n",
            "• opportunity planning, opportunity management\n",
            "• quotation and order management\n",
            "• Pricing\n",
            "• Organizational Management and Billing\n",
            "• Customizations of Surveys\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "B.E in CSE\n",
            "\n",
            "Padmanava College of Engineering\n",
            "\n",
            "2009\n",
            "\n",
            "St. Joseph's convent school\n",
            "\n",
            "\n",
            "\n",
            "2003\n",
            "\n",
            "SKILLS\n",
            "\n",
            "CRM (10+ years), CUSTOMER RELATIONSHIP MANAGEMENT (10+ years), TESTING (10+ years),\n",
            "UI (10+ years), USER INTERFACE (10+ years)\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "Other Skills:\n",
            "\n",
            "CRM Middleware:\n",
            "\n",
            "• Worked on downloading initial and delta download between ECC and CRM,\n",
            "CRM and MSA.\n",
            "• Monitoring middleware data between ECC and CRM.\n",
            "• Monitoring Queues and error handling of BDocs.\n",
            "• Worked on subscriptions and Publications, Replication Objects.\n",
            "\n",
            "SAP ECC Sales and Distribution:\n",
            "\n",
            "• Strong Understanding of SAP Customizing and Detailed knowledge of core SD functions such\n",
            "as Item Categories, Text Determination, output determination, taxes\n",
            "• Customer Master and Material Master data, item proposal, variant configuration, Product\n",
            "hierarchy\n",
            "• Sales document types (Orders, Returns, CMR, DMR)\n",
            "• Billing and Pricing concept, worked on bill plans\n",
            "• Sales Enterprise structure\n",
            "• Copy control, Incompletion log, Material listing and Exclusion\n",
            "• Partner determination, Customization of Account groups\n",
            "• Worked with cross-functional teams during development and configuration activities to ensure\n",
            "impact to other SAP modules and processes is considered.\n",
            "\n",
            "SAP CRM Skills:\n",
            "• CRM Sales and Service order management (Extensive experience in configuration for Text\n",
            "Determination Procedures, Status Profile, Org. Data Determination and Transaction Types)\n",
            "\n",
            "• SAP Fiori (creation of test data and application testing in different landscapes including browser\n",
            "testing)\n",
            "• SAP Mobile Sales (creation of test data and system set up)\n",
            "• Well versed in base customizing and WEBUI configuration along with CRM Tables.\n",
            "• Hands on experience in CRM middleware (creation of sites, subscription, publication, checking\n",
            "bdocs, idocs, download objects) and trouble shooting.\n",
            "• In depth knowledge in CRM One Order Framework.\n",
            "• Extensive experience in the configuration of Web UI for multiple Business Roles, Actions,\n",
            "Navigation Bar Profile.\n",
            "\n",
            "Competencies and Skills:\n",
            "\n",
            "\n",
            "\n",
            "• CR-100 (BP, Product, Org model, Partner/Text determination, Transaction type, Item categories,\n",
            "Territory)\n",
            "• CR-300\n",
            "• CRM Mobile Sales\n",
            "• CRM Middleware Basics\n",
            "• Basic Debugging (ABAP)\n",
            "• Knowledge on Idocs (set-up, filtration, reprocessing)\n",
            "\n",
            "Testing:\n",
            "• Experience in SAP CRM Module (sales and service) with testing\n",
            "• Good understanding of application testing process.\n",
            "• Coordinated with SAP CRM technical team members to understand testing functionalities\n",
            "• Written Test cases for different CRM modules (Account Management, opportunity, activity\n",
            "management, sales order creation) Sales & Service.\n",
            "• Managed issue logs / defects and subsequent closures.\n",
            "\n",
            "Basic Debugging:\n",
            "Knowledge of ABAP Debugging, Basic ABAP (Tables, data elements, Working with Table\n",
            "Maintenance Generator, Creating a Transaction Variant, Creating an SAP Area Menus, Find the\n",
            "SAP IMG Customizing Activity from the Table Name, basic knowledge of Smartforms) Sridevi H\n",
            "Bangalore, Karnataka - Email me on Indeed: indeed.com/r/Sridevi-H/63703b24aaaa54e4\n",
            "\n",
            "To further my career with a growth-oriented firm that will allow me to utilize my experience and\n",
            "knowledge as a Technical /Project Lead.\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "Principal System Engineer\n",
            "\n",
            "Aricent Technologies\n",
            "\n",
            "Infosys\n",
            "\n",
            "Technical Lead\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "M.S in Software Systems\n",
            "\n",
            "BITS Pilani -  Pilani, Rajasthan\n",
            "\n",
            "B.E. in Computer Science\n",
            "\n",
            "Board of Technical Education\n",
            "\n",
            "SKILLS\n",
            "\n",
            "Networking/Platform/Drivers/Vxworks\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "Key Strengths\n",
            "• Over 15 years of experience in Ethernet Data Communication Technology Ethernet Routing\n",
            "Switches, Metro Ethernet Routing Switches, Platform and Wireless\n",
            "• Good knowledge of Real Time operating Systems (Vxworks) and Drivers\n",
            "• Highly skilled in performing analytical and logic building functions to provide feasible solutions\n",
            "to problems\n",
            "• Brilliant interpersonal coordination and communication skills\n",
            "• Competent at leading, managing and training teams on different aspects of data\n",
            "communication systems\n",
            "\n",
            "Technical Skill Set\n",
            "SYSTEMS WORKED ON * Data communication -Multi Service Transport Network Controller Cards,\n",
            "Ethernet Routing Switch,\n",
            "DOMAIN KNOWLEGDE\n",
            "* Enterprise Router -L2, L3 protocols (MLT, LACP, BGP, STP, SMLT, SLPP, Provider Bridge, IPFIX,\n",
            "VRF, RSP Fastpath)\n",
            "\n",
            "https://www.indeed.com/r/Sridevi-H/63703b24aaaa54e4?isid=rex-download&ikw=download-top&co=IN\n",
            "\n",
            "\n",
            "* Platform -Task Architecture, Logging, , File System, Debugging tools, Crash analysis, Chassis\n",
            "Management\n",
            "* Wireless- 802.11 Split AP Architecture, WMM 802.11 E\n",
            "\n",
            "OPERATING SYSTEMS and LANGUAGE PROFICIENCY/HARDWARE PLATFORM * Programming/\n",
            "Library/Platform - C, Visual Basics, Unix, RTOS-VxWorks, Windows, Power PC based processor,\n",
            "TOOLS\n",
            "* Clarify, Clearcase, Source Insight, Network Traffic Simulators like IXIA, Smart Bits, Network\n",
            "Protocol Analyzers like Ethereal and WireShark.\n",
            "\n",
            "DATABSE * Oracle, MS Access, MySQL\n",
            "REWARDS AND RECOGNITIONS\n",
            "* Spot Awards, Program Level Awards Infosys, Aricent\n",
            "* Individual Excellence Award 2010 Infosys\n",
            "* Leadership Quotient Award 2014 Aricent\n",
            "* Client Appreciation Award 2016 Aricent\n",
            "* Engineering Excellence Award 2016 Cisco\n",
            "\n",
            "SOFT SKILLS\n",
            "Soft skill trained and certified in the areas like Interpersonal Effectiveness, Client Interfacing\n",
            "Skills, Cross Cultural Skills,\n",
            "&amp;Team Management\n",
            "\n",
            "Projects Handled in Aricent\n",
            "Project 01: TNC Controller card for MSPP and MSTP Optical network\n",
            "Duration: From Date: Nov 2014 to till date\n",
            "Designation: Principal System Engineer\n",
            "Client: Cisco\n",
            "\n",
            "Role:\n",
            "1. Design and Development of Network Driver/Pseudo Network Driver for new controller card with\n",
            "Broadcom SDK integration and Driver Implementation Tasks include Driver design for new Chip,\n",
            "Broadcom SDK compilation in VxWorks, Integration and Writing driver using Broadcom SDK.\n",
            "2. Design and Development of Broadcom Mini Driver Kit Integration in new controller card\n",
            "3. Design and Development of Features like GDT, ANSI-ETSI on Multishelf\n",
            "\n",
            "4. Front ending the Different Releases\n",
            "5. Technical Guidance and Backlog Reduction Activities\n",
            "6. Solving Critical Customer issues\n",
            "Few examples of critical issues solved in the TNC which fetched client appreciations\n",
            "Flash Mgr Stuck issue\n",
            "UsbMgr Stuck issue\n",
            "Silent Reboot caused in the standby controller\n",
            "Ipv6 connectivity failure every 2-3 hours\n",
            "Arp6Show causing crash in telnet session\n",
            "7. Client interaction and customer network/Test Team Network debugging\n",
            "8. Mentoring the team\n",
            "\n",
            "Project 02: VSM IPSec for ASR9K\n",
            "\n",
            "\n",
            "\n",
            "Duration: From Date: Feb 2013 to Oct 2014\n",
            "Designation: Senior Technical Lead\n",
            "Client: Cisco\n",
            "\n",
            "Support for IPsec on ASR9K routers. VSM Service module is extended to support IPSec Service\n",
            "on ASR9K. In order to achieve the Time to market, in the first phase IPSec management, control\n",
            "and data plane are not integrated with IOS-XR. VSM card while plugged inside ASR9K chassis,\n",
            "will provide the IPSec functionality. From an ingress LC, traffic requiring IPSec functionality\n",
            "(encryption or decryption) will be sent to VSM card. Upon completing the crypto operation, traffic\n",
            "will be forwarded to the destination egress LC to be sent out of ASR9K system.\n",
            "Role:\n",
            "1. Initial Sessions for the team members on overall architecture\n",
            "2. Coordinating with team members and technical help to the team\n",
            "3. Initial investigation using Intel DPDK compilation, launch VMs etc.\n",
            "4. Initial investigation on High Availability Design\n",
            "5. Design/Development of Keep alive functionality between Control plane and Data plane agents\n",
            "6. Design/Development of integrating CDP in Control Plane\n",
            "7. Design/Development of having CDP in the Linux Data plane\n",
            "\n",
            "Prior Experience Outside Aricent\n",
            "Company worked for: INFOSYS LIMITED\n",
            "Duration: From Date: 03 Sep 2007 To Date: 2 Jan 2013\n",
            "Designation: Technology Lead\n",
            "\n",
            "Product: MERS and ERS Routers\n",
            "Client: Avaya\n",
            "Project 01: Ethernet Routing Switch - North American OEM\n",
            "The Ethernet Routing Switch is a proven, tested, resilient intelligent network solution that scales,\n",
            "delivering hundreds of Gigabits per second and hundreds of millions of packets per second of\n",
            "performance to the core. This flexible switch reduces the complexity of network design, making\n",
            "it ideal for midsize-to-large enterprise campuses and data centers. Its switching architecture is\n",
            "based on Network Processing Units (NPU)\n",
            "\n",
            "This project aims at design, development and sustenance of Enterprise Routers.\n",
            "\n",
            "Responsibilities/Activities\n",
            "• Bug Fixing and crash analysis in area of Routing and system architecture\n",
            "• Trouble Shooting the live customer network to understand the issue provide work around and\n",
            "collect data\n",
            "• As Sustenance team member and lead resolved/supervised critical customer and design issues.\n",
            "- Critical customer issues in Area of Vxworks Stack, SSH, STP\n",
            "device drivers, BGP protocol, MLT, LACP, CFM\n",
            "\n",
            "Some good issues solved in different areas of the product which are in memory are\n",
            "- Solving tftp hang issue in Vxworks Stack\n",
            "- Providing task delete hook for the graceful task deletion for SSH Hang issue\n",
            "- Solving BGP indirect neighbor issue by trouble shooting live customer network\n",
            "- Providing analysis and solution to a non-reproducible SSH hang issue\n",
            "- Providing analysis on inter-op issue with proprietary IO card with CISCO\n",
            "\n",
            "\n",
            "\n",
            "- Fix for CF card crash issue\n",
            "- Quick solution provided in RSP Code for handling traffic on STP blocked port for IP Traffic.\n",
            "- Provided design/technical inputs for feature development \"Sys log Support through SSH\n",
            "Portforwarding \"\n",
            "- Supervised feature \"Federal IA Library\" design and implementation\n",
            "• Maintain and setting up of scaled up stability network to verify the Stability of the product\n",
            "• Training and mentoring new personnel in the project\n",
            "• Review of Designs, Enhancements &amp; Major Bug Fixes.\n",
            "-Provided Code /Design Review comments and testing guidance and testing scenarios.\n",
            "• Design Support to Product Test teams for newly developed features.\n",
            "• Design and Development of enhancements.\n",
            "• As a lead involved in tracking deliverables, estimation, status reporting (to the customer),\n",
            "productivity and quality tracking.\n",
            "• Additionally providing consultation to test team in their deliverables\n",
            "• Ensuring high quality of deliverables through reviews and defect prevention.\n",
            "\n",
            "Project 02: Metro Ethernet Routing Switch - North American OEM\n",
            "\n",
            "Responsibilities/Activities\n",
            "• Worked in the various capacities -Technical Lead, Designer,\n",
            "• Resolving Critical customer issues in quick turnaround time\n",
            "• Driving the sustenance team size of 10 by providing the technical assistance and necessary\n",
            "sessions and trainings in turn increase the productivity of the team\n",
            "• Conducting weekly bug-scrub meetings to ensure the work in track\n",
            "• One of the key code reviewers in the program to ensure the proper quality of the product\n",
            "delivered.\n",
            "• Defect analysis, Knowledge management are the other key responsibilities\n",
            "• Training and mentoring new personnel in the project.\n",
            "\n",
            "Company worked for: HUAWEI TECHNOLOGIES\n",
            "Duration: From Date: 07 Jun 2004 To Date: 18 May 2007\n",
            "Designation: SOFTWARE ENGINEER\n",
            "\n",
            "Client: Huawei China\n",
            "\n",
            "Project 01: DOPRA\n",
            "\n",
            "Description of the project\n",
            "DOPRA is the platform for telecom products. It is a proprietary platform and has company internal\n",
            "customers. It has main two planes, system management and system service planes and several\n",
            "sub modules.\n",
            "I have successfully worked on the following modules.\n",
            "\n",
            "Module - MML INI Parser Tool\n",
            "MML is Configuration Tool used in communication equipments\n",
            "This Configuration Tool has set of default and user defined commands. INI Parsing tool is a tool\n",
            "which accepts MML Commands in certain grammar and generates Resource file and Binary File\n",
            "respectively which will be read by server to resister the commands.\n",
            "Involved in the development, testing, verification of the module on windows.\n",
            "\n",
            "\n",
            "\n",
            "Module - Man Machine Language\n",
            "MML is a configuration tool widely used in communication equipments. It uses Client/Server\n",
            "architecture. MML server communicates with both the client and the APP in the equipment.\n",
            "It receives MML commands inputted by users from the client and relays it to APP to process\n",
            "it. After acquiring the processing result, the server generates a MML report and sends it back\n",
            "to the client. It interacts with other system modules. Connection Management, Authorization\n",
            "Management, Command Process, Data Synchronization, Event Notification, Command Parsing,\n",
            "LOG/ALARM Handling are some of the functions of MML Server.\n",
            "Involved in the development, defect fixing and verification of the module on windows, Linux and\n",
            "vxworks platforms Involved in several release activities.\n",
            "\n",
            "Module - Configuration Management\n",
            "Configuration Management Module is core module of System Management. Its main function\n",
            "is to define specifications for configuration management interface between the configuration\n",
            "tool layer and the application layer, and provide related configuration command communication\n",
            "mechanism. Any information that can be modified by the user/application and that affects the\n",
            "functionality of the application can be regarded as configurable data. All configuration commands\n",
            "can be sent to Configuration Management Module using a common interface type.\n",
            "Configuration Data Management Module is a supplementary optional component that can be\n",
            "loaded to provide a persistent storage (&amp; retrieval) mechanism for applications' static\n",
            "configuration data.\n",
            "Involved in the defect fixing and feature enhancement of the module on windows, Linux and\n",
            "vxworks platforms Involved in several release activities.\n",
            "\n",
            "Module - TL1\n",
            "Transaction Language 1 (TL1) is a widely used, \"legacy\", management protocol in\n",
            "telecommunications. It is a cross-vendor, cross-technology man-machine language, and is\n",
            "widely used to manage Synchronous Optical Networks (SONET) . It is defined for operation\n",
            "system/ network element (machine-to-machine) interfaces. TL1 corresponds to the User System\n",
            "Language (USL), which is the language for human-to machine interactions. It is used for managing\n",
            "network elements in a network. TL1 Module is an interface between an Application and Client.\n",
            "Client sends the TL1 Commands to perform some configuration operations in the Applications.\n",
            "TL1 module process the client text TL1 commands according to standard specification TL1 GR\n",
            "831 and interacts with the Configuration management module and Convert Response messages\n",
            "back to TL1 Response messages\n",
            "Involved in development, verification and customer and release activities. I was a module lead\n",
            "for this project.\n",
            "\n",
            "Module - QX\n",
            "The Qx interface is a company proprietary application layer protocol between target and the GUI\n",
            "of NMS. By this protocol, NE can communicate with SCC (System Communication and Control)\n",
            "software in different operation system. Each command has defined format. Commands are given\n",
            "in binary form. Qx Module acts as an interface between the Client and Application.\n",
            "Involved in development, verification and customer and release activities. I was a module lead\n",
            "for this project.\n",
            "\n",
            "Role: Designer/Developer/ Reviewer/\n",
            "\n",
            "\n",
            "\n",
            "Responsibility: Designing and coding various modules Involvement in peer review and overall\n",
            "review activities and project discussions Coordinating the development cycle Training team\n",
            "members and solving project related issues configuration management of the project using Clear\n",
            "Case\n",
            "Duration: From June 2004 to Sep 2006\n",
            "Hardware: X86, CPCI, ATCA\n",
            "Software: C++, C\n",
            "Project2: Wireless LAN - 802.11 MAC (Split AP Architecture)\n",
            "Description of the project\n",
            "Wireless LAN 802.11 describes MAC and PHY. Wireless stations are connected to form a basic\n",
            "service area which is controlled by a base station called Access Point. Access Point is a special\n",
            "device which basically acts as a bridge between wired and wireless media connected to a\n",
            "distributed system generally Ethernet. Several Access Points can be connected to a distribution\n",
            "media to form an extended service set.\n",
            "In split AP architecture AP's connect to a central controller called Access Controller in short\n",
            "AC. AP has the minimal functionalities such as receiving the 802.11 data from the radio and\n",
            "forwarding data and management frames to AC, Power management, Advertising beacons,\n",
            "handling control frames. Management operations such as Association, Authentication, Handling\n",
            "frames, conversion between […] 802.3 will be done by AC.\n",
            "I was involved in the development of feature development, defect analysis, testing activities in\n",
            "the CLI, Frame handling, Association and Beacon advertisement modules.\n",
            "Module: WLAN Support for WMM 802.11 E Qos Requirements\n",
            "WMM is a protocol designed by the Wi-Fi forum to provide quality of service to wireless traffic.\n",
            "This project basically deals with providing WLAN support for WMM module, this includes handling\n",
            "Qos frames in the Uplink down link data flow, Priority mapping for Qos frames, Fragmentation\n",
            "and Reassembly of the Qos frames, Security Related modifications for Qos Frames, Power\n",
            "management of Qos stations etc.\n",
            "I was involved in the design, review, coding of the Uplink, Down link Data Flow, Fragmentation\n",
            "and Reassembly of the Qos frames.\n",
            "\n",
            "Role: Developer\n",
            "Responsibility: To design, and code the necessary changes. Design test scenarios for the design\n",
            "verification of the feature enhancements. Ensure proper quality of the product delivered. Smoke\n",
            "testing of all the features in each release Performance testing and log record maintenance\n",
            "Configuration Management for feature enhancement projects using Clear case tool\n",
            "Duration: From: Sep 2006 - May 2007\n",
            "Hardware: Vxworks, Windows\n",
            "Software: C\n",
            "Company worked for: ALBERTSONS INTERNATIONAL PRIVATE LIMITED\n",
            "Duration: From Date: 16 Jun 2000 To Date:29 Oct 2001\n",
            "Designation: SOFTWARE ENGINEER\n",
            "Project Name Application Software Development\n",
            "\n",
            "Description of the project\n",
            "Software for guest house, Fisheries Account management, Liquor wholesale. restaurants\n",
            "\n",
            "Role: Designer/Developer/ Reviewer/Customer Support\n",
            "\n",
            "\n",
            "\n",
            "Responsibility: Designing and coding above mentioned projects independently Involvement\n",
            "in requirement collection, prototype building, installation and support Coordinating the\n",
            "development cycle\n",
            "Duration: From June 2000 to Oct 2001\n",
            "Hardware: X86\n",
            "Software: VB, C, MSACCESS\n",
            "Management Skill Set\n",
            "• Release Planning\n",
            "• Work assignment and Follow up\n",
            "• Preparation of weekly bug scrub for customer and Conducting Weekly Bug scrub Meetings with\n",
            "the team\n",
            "• Monthly Billing\n",
            "• Monthly Milestone Report Preparation\n",
            "• Monthly Metrics Report Preparation\n",
            "• Monthly OPS Review Report Preparation and Meetings with customer\n",
            "• Weekly OPS Preparation and Meetings with customer\n",
            "• TL9K Audit Preparation\n",
            "• Quarterly Defect Prevention and Analysis Report Preparation\n",
            "• Monthly CM Audit\n",
            "• Provided Macro and VB scripting and CQ queries for button click report generation\n",
            "\n",
            "SRIDEVI RAO H kimaya sonawane\n",
            "Thane, Maharashtra - Email me on Indeed: indeed.com/r/kimaya-\n",
            "sonawane/1f27a18d2e4b1948\n",
            "\n",
            "Quality education blended with sense of responsibility to utilize my professional as well as\n",
            "interpersonal skills that enables me to achieve the goals.\n",
            "\n",
            "Willing to relocate: Anywhere\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "Technical Support Engineer\n",
            "\n",
            "SAP -  Thane, Maharashtra -\n",
            "\n",
            "November 2016 to Present\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "BE in computer science\n",
            "\n",
            "SSVPS’s Late B. S. Deore College of Engineering ,Dhule -  Dhule, Maharashtra\n",
            "\n",
            "2011 to 2016\n",
            "\n",
            "SKILLS\n",
            "\n",
            "network engineers, Networking, CCNA, knowledge of Active Directory, DHCP, DNS ,\n",
            "Troubleshooting and fix Network related issues (2 years)\n",
            "\n",
            "CERTIFICATIONS/LICENSES\n",
            "\n",
            "CCNA(Cisco Certified Network Associate- Routing & Switching) , MCSA\n",
            "(Microsoft Certified Solution Associate)\n",
            "\n",
            "July 2016 to Present\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "PROFESSIONAL INTRESTS:\n",
            "• Leading and managing teams\n",
            "• Interacting with People\n",
            "CO CURRICULAR ACTIVITES:\n",
            "• Participated in \"Mech-Tricks\" in IMPULSE 2014 National Level Event.\n",
            "• Participated in \"Mech-Tricks\" in IMPULSE 2013 National Level Event.\n",
            "• Participated in \"Tech-Quiz\" in IMPULSE 2013 National Level Event.\n",
            "• Participated in \"Management Games\" Organised in Ganesh Utsav 2012.\n",
            "• Winner in \"Rangoli Competition\" Organised in Ganesh Utsav 2013.\n",
            "\n",
            "https://www.indeed.com/r/kimaya-sonawane/1f27a18d2e4b1948?isid=rex-download&ikw=download-top&co=IN\n",
            "https://www.indeed.com/r/kimaya-sonawane/1f27a18d2e4b1948?isid=rex-download&ikw=download-top&co=IN\n",
            "\n",
            "\n",
            "PERSONAL TRAITS:\n",
            "\n",
            "• Self Motivated\n",
            "• Adaptable\n",
            "• Confident\n",
            "• Team facilitator\n",
            "• Hard Worker Ayesha B\n",
            "Team member - Oracle\n",
            "\n",
            "Bangalore, Karnataka - Email me on Indeed: indeed.com/r/Ayesha-B/b2985be284dee3d6\n",
            "\n",
            "Seeking a position to utilise my skills and abilities in the industry that offers professional growth\n",
            "while being innovative, flexible and also to explore myself and utilise my potential to the growth\n",
            "of the company.\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "Team member\n",
            "\n",
            "Oracle -  Bangalore, Karnataka -\n",
            "\n",
            "August 2012 to Present\n",
            "\n",
            "Nature of duties:\n",
            "\n",
            "• Developed and deployed Oracle forms in FLEXCUBE CORPORATE.\n",
            "- I have developed Oracle Forms and deployed the same in application server, which is used as\n",
            "front end by the bank users.\n",
            "• Necessary coding changes of project are done in PL/SQL developer.\n",
            "- Necessary Procedures and Functions are defined as part of the project.\n",
            "• Was part of Internal Unit Testing and Unit Testing.\n",
            "- I have prepared Test cases for forms and tested the same and was part of Internal Unit Testing.\n",
            "• Documentation.\n",
            "- I have prepared Functional Specification, Desgin Specification and Project specification\n",
            "documentation.\n",
            "• Installed and worked on FLEXML.\n",
            "• Exported and Imported schemas.\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "B.E. in CSE\n",
            "\n",
            "Atria Institute of Technology -  Bangalore, Karnataka\n",
            "\n",
            "2012\n",
            "\n",
            "Pre University Education -  Bangalore, Karnataka\n",
            "\n",
            "2008\n",
            "\n",
            "C.B.S.E.\n",
            "\n",
            "Sindhi High School -  Bangalore, Karnataka\n",
            "\n",
            "2006\n",
            "\n",
            "https://www.indeed.com/r/Ayesha-B/b2985be284dee3d6?isid=rex-download&ikw=download-top&co=IN\n",
            "\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "SOFT SKILLS\n",
            "\n",
            "* Sincere and Hardworking in nature\n",
            "* Highly Dedicated towards work\n",
            "\n",
            "* Efficient Individual and Team Player\n",
            "* Goal Oriented & Self Motivated\n",
            "\n",
            "IT Literacy Ashalata Bisoyi\n",
            "Transaction Processor - Oracle India Private Limited\n",
            "\n",
            "Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Ashalata-Bisoyi/cf02125911cfb5df\n",
            "\n",
            "To secure a position an esteem organization with good working culture that will help my career\n",
            "in the field of finance through my sincerity, hard works and skills.\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "Transaction Processor\n",
            "\n",
            "Oracle India Private Limited -\n",
            "\n",
            "April 2016 to Present\n",
            "\n",
            "2 Year of experience with Oracle India Private Limited in expense team. My work is auditing of\n",
            "expense reports of employees of all the countries, handling queries through emails and calls also.\n",
            "JOB DESCRIPTION\n",
            "• Auditing of expense reports of the employees for all the countries and working on service portal\n",
            "(Answering queries through email)\n",
            "• Handling the team in absence of seniors.\n",
            "• Working on Payment Rejections, export of expense reports to AP.\n",
            "• Take care of running Backlog, Having knowledge about travel advance.\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "Master of Finance and Control in MFC\n",
            "\n",
            "Khallikote Autonomous college -  Brahmapur, Orissa\n",
            "\n",
            "2015\n",
            "\n",
            "Bachelor in Commerce\n",
            "\n",
            "Berhampur university -  Brahmapur, Orissa\n",
            "\n",
            "2013\n",
            "\n",
            "Accounting\n",
            "\n",
            "Science College, Hinjilicut -  Brahmapur, Orissa\n",
            "\n",
            "2010\n",
            "\n",
            "Education\n",
            "\n",
            "Council of Higher Secondary -  Orissa, IN\n",
            "\n",
            "2008\n",
            "\n",
            "Government girls High school -  Hinjilikatu, Orissa\n",
            "\n",
            "https://www.indeed.com/r/Ashalata-Bisoyi/cf02125911cfb5df?isid=rex-download&ikw=download-top&co=IN\n",
            "\n",
            "\n",
            "Board of Secondary Education -  Orissa, IN\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "• Good analytical skills and flexible in work atmosphere.\n",
            "• Able to handle complex situation under process\n",
            "• Willingness to learn\n",
            "• Ability to meet deadlines\n",
            "• Every time accept the new challenges\n",
            "\n",
            "OTHER QUALIFICATIONS\n",
            "• DOEACC O LEVEL\n",
            "• M.S. OFFICE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQSe2-BOYlWN"
      },
      "source": [
        "__Question 4__: Why did we shuffle the data?<br> \n",
        "Why did we employ mini batches?<br>\n",
        "Reasearch the term __epoch__ in machine learning. How many epochs of training do we employ?<br>\n",
        "__Task 8__: Next, we choose one resumee and print it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFGKoHVXY1pL"
      },
      "source": [
        "resume = None\n",
        "\n",
        "print( resume )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iF_jyeVJ5b0"
      },
      "source": [
        "__Task 9__: we process this resumee using __nlp__. Print for all items in __doc.ents__ the predicted label and the corresponding text. Then print the correct labels and their corresponding text for that resumee with data from __y_test__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAyrdyfbnQR"
      },
      "source": [
        "doc = nlp( resume )\n",
        "\n",
        "# TODO\n",
        "# print for all the items in doc.ents the predicted label and the corresponding text\n",
        "\n",
        "for item in doc.ents:\n",
        "\n",
        "# TODO\n",
        "# print the correct labels and their corresponding text for that resumee with data from y_test\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTjZw4RVeB87"
      },
      "source": [
        "__Question 5__: What labels did the model predict correctly?<br> \n",
        "Where appeared problems?<br> \n",
        "How can you explain the problems?<br>\n",
        "__Question 6__: We can evaluate the performance of the model using 4 metrics: the __Accuracy__, the __Precision__, the __Recall__ and __F1__.<br>\n",
        "Inform yourself on these metrics. How are they defined? Explain the concept of __True Positive__, __True Negative__, __False Positive__ and __False Negative__. Use these to define  the __Accuracy__, the __Precision__, the __Recall__ and __F1__, and also give the formula for each of these.<br>\n",
        "__Task 10__: Complete the following code. Call __make_bilou_df__ with a resume from the test set and store result in __bilou_df__ variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5M-ArsDtzFd",
        "scrolled": true
      },
      "source": [
        "from spacy.gold import biluo_tags_from_offsets\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "## returns a pandas dataframe with tokens, prediction, and true (Gold Standard) annotations of tokens\n",
        "def make_bilou_df(nlp,resume):\n",
        "    \"\"\"\n",
        "    param nlp - a trained spacy model\n",
        "    param resume - a resume from our train or test set\n",
        "    \"\"\"\n",
        "    doc = nlp(resume[0])\n",
        "    bilou_ents_predicted = biluo_tags_from_offsets(doc, [(ent.start_char,ent.end_char,ent.label_)for ent in doc.ents])\n",
        "    bilou_ents_true = biluo_tags_from_offsets(doc, [(ent[0], ent[1], ent[2]) for ent in resume[1][\"entities\"]])\n",
        "\n",
        "    \n",
        "    doc_tokens = [tok.text for tok in doc]\n",
        "    bilou_df = pd.DataFrame()\n",
        "    bilou_df[\"Tokens\"] =doc_tokens\n",
        "    bilou_df[\"Tokens\"] = bilou_df[\"Tokens\"].str.replace(\"\\\\s+\",\"\") \n",
        "    bilou_df[\"Predicted\"] = bilou_ents_predicted\n",
        "    bilou_df[\"True\"] = bilou_ents_true\n",
        "    return bilou_df\n",
        "\n",
        "## TODO call method above with a resume from test set and store result in bilou_df variable.\n",
        "bilou_df = make_bilou_df( nlp, None )\n",
        "display(bilou_df)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGKyhMETJ5b1"
      },
      "source": [
        "Inform yourself on the [BILUO](https://spacy.io/usage/linguistic-features#accessing-ner) scheme.<br>\n",
        "__Question 7__: Why do you think is it better to tag entities using this scheme (consider names of humans, descriptions of items in a shop)?<br>\n",
        "__Task 11__: employ pandas dataframe api to get a subset where predicted and true labels are the same. Compute the accuracy using the formula you researched above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWRI3IfluPD7"
      },
      "source": [
        "## TODO bilou_df is a pandas dataframe. Use pandas dataframe api to get a subset where predicted and true are the same. \n",
        "same_df = None\n",
        "## TODO compute the accuracy \n",
        "accuracy = None\n",
        "\n",
        "print(\"Accuracy on one resume: \",accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P4EgefioE-Q"
      },
      "source": [
        "The __accuracy__ is not 100%. Therefore, we want to have a look at those tokens, where the predicted and the true value differ.<br>\n",
        "__Task 12__: create a dataframe diff_df where the predicted values and the true values differ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdHFX1cMn-r6"
      },
      "source": [
        "# TODO create a dataframe diff_df where the predicted values and the true values differ\n",
        "diff_df = None\n",
        "display(diff_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWvyiCokonUI"
      },
      "source": [
        "Since we only considered one resumee, we now make this comparison for the whole test set.<br>\n",
        "__Task 13__: Complete the following code for the computation of the overall accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bidqT9GjovAg"
      },
      "source": [
        "doc_accuracy = []\n",
        "\n",
        "for i in range( len( x_test ) ):\n",
        "\n",
        "  resume = None\n",
        "\n",
        "  bilou_df = make_bilou_df(nlp,resume)\n",
        "\n",
        "  same_df = None\n",
        "\n",
        "  doc_accuracy.append( None )\n",
        "\n",
        "total_acc = np.mean( doc_accuracy )\n",
        "print(\"Accuracy: \",total_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL7GE3RQpzbg"
      },
      "source": [
        "So we got an __accuracy__ of about 90% on average. This is quite good considering, that we only considered about 300 cases for training.<br>\n",
        "__Task 14__: Next, we want to find out, what the model did, when it went wrong. We only consider 5 resumees.<br>\n",
        "Complete the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y02Pkxriq8GM"
      },
      "source": [
        "for i in range( 5 ):\n",
        "\n",
        "  resume = None\n",
        "\n",
        "  bilou_df = make_bilou_df(nlp,resume)\n",
        "\n",
        "  difference_df = None\n",
        "\n",
        "  # TODO: print, where the labels from Spacy and the annotation differ. Print the text, the predicted and the true labels."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r21TdjPrt7P"
      },
      "source": [
        "__Question 8__: What was predicted, when the prediction differed from the true label?<br>\n",
        "What do you think is necessary for computing the accuracy on token level?<br> \n",
        "What is the advantage of computing the accuracy on token level?<br>\n",
        "__Task 15__: Complete the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZGOVg2U20V1"
      },
      "source": [
        "## TODO cycle through chosen_entity_labels and calculate metrics for each entity using test data\n",
        "data = []\n",
        "for label in chosen_entity_labels:\n",
        "    ## variables to store results for all resumes for one entity type\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "    for i in range( len( x_test ) ):\n",
        "        ## use make_bilou_df on each resume in our test set, and calculate for each entity true and false positives,\n",
        "        ## and false negatives. \n",
        "\n",
        "        resume = None\n",
        "        \n",
        "        tres_df = make_bilou_df(nlp,resume)\n",
        "\n",
        "        ## calculate true false positives and false negatives for each resume\n",
        "        \n",
        "        tp = None\n",
        "        \n",
        "        fp = None\n",
        "        \n",
        "        fn = None\n",
        "\n",
        "        ## aggregate result for each resume to totals\n",
        "        true_positives = true_positives + None\n",
        "        false_positives = false_positives + None\n",
        "        false_negatives = false_negatives + None\n",
        "    \n",
        "    print(\"For label '{}' tp: {} fp: {} fn: {}\".format(label,true_positives,false_positives,false_negatives))\n",
        "    \n",
        "    ## TODO Use the formulas you learned to calculate metrics and print them out\n",
        "    ## also: prevent division by zero without raising errors. Explain your choice\n",
        "    \n",
        "    row = [label,precision,recall,f1]\n",
        "    data.append(row)\n",
        "\n",
        "## make pandas dataframe with metrics data. Use the chosen entity labels as an index, and the metric names as columns. \n",
        "metric_df = pd.DataFrame( data, columns = [ \"Label\", \"Precision\", \"Recall\", \"F1\" ] )\n",
        "display(metric_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMKMlJswAqUZ"
      },
      "source": [
        "__Question 9__: Explain from these statistics how well __nlp__ performs.<br>\n",
        "__Task 16__: Compute for each metric (Precision, Recall, F1) the mean values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_gEZTQy5KTr"
      },
      "source": [
        "for label in [ \"Precision\", \"Recall\", \"F1\" ]:\n",
        "    \n",
        "    # Compute mean and print"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q1rvvhfBoN9"
      },
      "source": [
        "__Question 10__: What do you learn, when you compare the performance of the model on the token level with the performance of the model on the global level from above?<br>\n",
        "Next, we prepare data for flair."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vkzBYIlDbLe"
      },
      "source": [
        "train = [ [ x_train[ i ], y_train[ i ] ] for i in range( len( x_train ) ) ]\n",
        "\n",
        "test = [ [ x_test[ i ], y_test[ i ] ] for i in range( len( x_test ) ) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5NC7MIJJ5b6"
      },
      "source": [
        "__Task 17__: Complete the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBfdFr1qNKBv"
      },
      "source": [
        "# prepare data\n",
        "training_data_as_bilou = [make_bilou_df(nlp,res) for res in train]\n",
        "\n",
        "test_data_as_bilou = [make_bilou_df(nlp,res) for res in test]\n",
        "\n",
        "\n",
        "# set up paths\n",
        "path_to_training_file = os.getcwd() + \"/training_data.csv\"\n",
        "\n",
        "path_to_test_file = os.getcwd() + \"/test_data.csv\"\n",
        "\n",
        "\n",
        "\n",
        "# make sure, that if the corresponding files exist, they are emptied\n",
        "if os.path.isfile( path_to_training_file ):\n",
        "\n",
        "  open( path_to_training_file, \"w\" ).close()\n",
        "\n",
        "if os.path.isfile( path_to_test_file ):\n",
        "\n",
        "  open( path_to_test_file, \"w\" ).close()\n",
        "\n",
        "\n",
        "# open empty files\n",
        "training_file = open( path_to_training_file, \"a\", encoding = \"utf-8\" )\n",
        "    \n",
        "test_file = open( path_to_test_file, \"a\", encoding = \"utf-8\" )\n",
        "\n",
        "\n",
        "for item in training_data_as_bilou:\n",
        "\n",
        "  # TODO remove all tokens like \"\", \" \", \"\\n\" by ignoring them\n",
        "  # for all other tokens do the following:\n",
        "  # create a string s: s = token + \" \" + label + \"\\n\"\n",
        "  # if the label is \"-\", then write s = token + \" O\\n\"\n",
        "  #\n",
        "  # write this newly created string to file\n",
        "  # if this newly created string contains \".\", then also write a \n",
        "  # newline to file that only contains \"\\n\"\n",
        "  #\n",
        "  # Using this scheme, each line in the resulting files corresponds either to an empty line or a token.\n",
        "  # Flair assembles a block of nonempty lines into a sentence. Therefore, the empty line\n",
        "  # is a signal for Flair that the current sentence is finished. Therefore, we extracted\n",
        "  # the whitespaces above.\n",
        "\n",
        "for item in test_data_as_bilou:\n",
        "    \n",
        "  # TODO the same as above.\n",
        "\n",
        "\n",
        "training_file.close()\n",
        "\n",
        "test_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V5trnr4gXa9"
      },
      "source": [
        "Start Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "630pwinWhXWo"
      },
      "source": [
        "pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKoPUsQGgaEE"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "\n",
        "\n",
        "# your training file name\n",
        "data_folder = os.getcwd() \n",
        "\n",
        "train_file = \"training_data.csv\"\n",
        "\n",
        "# your training file name\n",
        "test_file = \"test_data.csv\"\n",
        "\n",
        "# when we wrote the data files, each row was either empty to signal the end\n",
        "# of a sentence to Flair, or the line contained a token, a white space and a label.\n",
        "# In the next line, we assign, that the token is the \"text\", and that the label is \n",
        "# \"ner\" label\n",
        "columns =  {0: 'text', 1: 'ner'}\n",
        "\n",
        "## Now load our csv into flair corpus\n",
        "corpus = NLPTaskDataFetcher.load_column_corpus(data_folder,column_format=columns,\n",
        "                                               train_file=train_file,\n",
        "                                               test_file=test_file)\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}